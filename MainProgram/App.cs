using Newtonsoft.Json;
using System.Collections.Concurrent;
using DeepSeekApi;
using System.Dynamic;
namespace MainProgram;
/// <summary>
/// 主程序
/// </summary>
public sealed class App
{
	public void Start()
	{
		//"能跟我说错大数据语言模型的工作原理吗？以及大数据语言模型是如何实现对话功能？还有推理功能？".AskDeepSeek().GetAwaiter().GetResult();
		//DeepSeekControl.Think.ShowInConsole(true);
		//DeepSeekControl.Answer.ShowInConsole(true);
		string json = "{\"id\":\"e7f2c9ca-6860-40a6-97ed-57799c1743c9\",\"object\":\"chat.completion\",\"created\":1742744422,\"model\":\"deepseek-reasoner\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"大数据语言模型（如GPT、PaLM等）的工作原理以及对话和推理功能的实现涉及多个复杂的技术环节。以下是分步解析：\\n\\n---\\n\\n### **一、大数据语言模型的核心工作原理**\\n#### 1. **架构基础：Transformer模型**\\n   - **自注意力机制（Self-Attention）**：通过计算输入序列中每个词与其他词的相关性权重，捕捉长距离依赖关系（例如“它”指代前文的某个名词）。\\n   - **位置编码（Positional Encoding）**：为词序列添加位置信息，避免传统RNN的顺序处理瓶颈。\\n\\n#### 2. **预训练（Pre-training）**\\n   - **训练目标**：通过无监督学习，在大规模文本数据（如书籍、网页）上完成“填空”任务（掩码语言模型）或“预测下一个词”（自回归生成）。\\n   - **数据规模**：模型参数（如GPT-3的1750亿参数）与训练数据量（数百GB到TB级文本）直接相关，通过海量数据学习语言统计规律。\\n\\n#### 3. **数学本质：概率建模**\\n   - 模型本质是学习一个概率分布 \\\\( P(w_{t} | w_{1}, w_{2}, ..., w_{t-1}}) \\\\)，即根据上下文预测下一个词的概率。\\n   - 通过Softmax函数输出词表中所有词的分布，选择高概率词（可通过采样策略调整生成多样性）。\\n\\n#### 4. **计算资源**\\n   - 训练需分布式计算（如GPU/TPU集群），利用并行化处理大规模矩阵运算（如矩阵乘法、梯度下降优化）。\\n\\n---\\n\\n### **二、对话功能的实现机制**\\n#### 1. **上下文感知（Context Window）**\\n   - 模型通过固定长度的上下文窗口（如GPT-3的2048个token）存储对话历史，每次生成新回复时重新编码整个上下文。\\n   - 通过自注意力机制动态关注对话中的关键信息（如用户提问的核心意图）。\\n\\n#### 2. **生成策略**\\n   - **贪心搜索（Greedy Search）**：直接选择概率最高的词，但可能导致重复。\\n   - **束搜索（Beam Search）**：保留多个候选序列，平衡生成质量与多样性。\\n   - **温度调节（Temperature）**：调整Softmax输出的熵值，控制生成结果的随机性（高温更发散，低温更保守）。\\n\\n#### 3. **对齐与微调（Alignment）**\\n   - **监督微调（SFT）**：在人工标注的高质量对话数据上进一步训练，优化回复的合理性和安全性。\\n   - **人类反馈强化学习（RLHF）**：通过人类对生成结果的评分，训练奖励模型（Reward Model），再通过PPO等算法优化生成策略。\\n\\n---\\n\\n### **三、推理功能的实现与局限性**\\n#### 1. **表面推理（Shallow Reasoning）**\\n   - **模式匹配**：依赖训练数据中类似问题的模板（如数学题“A有5个苹果，B有3个，共有多少？”可能在数据中出现过多次）。\\n   - **隐式逻辑链**：通过自注意力机制隐式捕捉数据中的逻辑关联（如“因A所以B”的文本模式）。\\n\\n#### 2. **显式推理技术**\\n   - **思维链（Chain-of-Thought, CoT）**：在输入中要求模型“逐步推理”，触发分步生成（例如先分解问题为子步骤）。\\n   - **工具调用（Tool Use）**：结合外部计算器、知识库等，将部分推理任务卸载到专用系统（如“计算2023年的闰年状态”）。\\n\\n#### 3. **局限性**\\n   - **符号推理缺陷**：无法真正处理形式逻辑（如一阶谓词逻辑）。\\n   - **幻觉（Hallucination）**：缺乏事实性验证机制，可能生成合理但不真实的内容。\\n\\n---\\n\\n### **四、总结：能力与边界**\\n- **对话**：通过上下文建模和生成策略实现连贯交互，本质是统计意义上的“模仿”。\\n- **推理**：依赖数据中的显性模式或特定Prompt设计，而非真正的逻辑演算。\\n- **核心驱动**：大数据量（学习语言规律）+ 大参数量（存储复杂模式）+ 计算架构（高效处理序列）。\\n\\n如需进一步探讨具体技术细节（如Transformer的数学推导或RLHF的实现），可继续深入。\",\"reasoning_content\":\"嗯，用户问的是关于大数据语言模型的工作原理，以及它们如何实现对话和推理功能的。首先，我需要确定用户对这些概念的基础了解程度。可能用户已经有一些基本知识，但想深入了解细节，或者他们可能刚开始接触这个领域。接下来，我需要分解问题，逐一解答每个部分：工作原理、对话功能和推理功能。\\n\\n首先，大数据语言模型的工作原理。这部分需要解释模型的基本结构，比如基于Transformer架构，预训练和微调的过程，以及如何利用海量数据进行训练。要提到自注意力机制，这是Transformer的核心，可能还需要说明模型是如何通过预测下一个词来学习语言模式的。同时，参数数量和计算资源的重要性也应该提到，比如像GPT-3这样的模型有上千亿参数，需要大量的计算能力。\\n\\n然后是对话功能的实现。这里需要讨论到微调阶段，可能使用监督学习和强化学习，比如人类反馈的强化学习（RLHF）。还要说明模型如何生成连贯的回复，通过上下文窗口来维护对话历史，保持对话的一致性。另外，对话策略，比如如何避免重复或矛盾的回答，可能也需要解释。\\n\\n关于推理功能，这部分可能比较复杂。需要说明模型如何通过模式识别和概率分布来处理看似需要逻辑推理的问题。可能提到思维链（Chain-of-Thought） prompting，或者模型在训练过程中如何隐式地学习到逻辑结构。同时，也要指出模型的局限性，比如依赖已有的数据模式，而非真正的抽象推理能力。\\n\\n在思考过程中，可能会疑惑用户是否了解深度学习和神经网络的基础。如果用户不熟悉，可能需要用更通俗的比喻，比如将模型比作大脑神经元网络。但用户的问题比较具体，可能已经有一定的基础，所以应该保持技术性，同时不过于晦涩。\\n\\n另外，需要确认是否要区分不同模型，比如GPT、BERT等的区别，但用户的问题比较通用，可能不需要深入各个模型的差异，而是聚焦在共性上。同时，可能要考虑用户的实际需求，比如他们是否想了解如何应用这些模型，或者是否有兴趣自己训练模型。但根据问题，主要集中在原理和功能实现上。\\n\\n还需要注意避免错误，比如不能将模型的推理能力等同于人类的逻辑推理，必须强调这是基于统计和模式匹配的。同样，在对话功能中，要提到模型没有真正的意识或理解，而是生成最可能的响应。\\n\\n最后，总结时需要将各部分串联起来，说明大数据语言模型通过海量数据学习语言模式，通过特定技术实现对话连贯性，并通过模式识别模拟推理能力，同时指出其局限性。这样用户可以得到一个全面的理解，同时意识到技术的当前边界。\"},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":27,\"completion_tokens\":1449,\"total_tokens\":1476,\"prompt_tokens_details\":{\"cached_tokens\":0},\"completion_tokens_details\":{\"reasoning_tokens\":524},\"prompt_cache_hit_tokens\":0,\"prompt_cache_miss_tokens\":27},\"system_fingerprint\":\"fp_5417b77867_prod0225\"}";
		dynamic sample = System.Text.Json.JsonSerializer.Deserialize<DynamicClass>(json, ConfigManager.Options)!;
		string test = sample.choices[0].message.content;
		test.ShowInConsole(true);
	}
}
